# Agent Inspector Multi-Agent Example Configuration
# Copy this file to .env in the examples directory:
# cp examples/.env.example examples/.env

# OpenAI Configuration (REQUIRED for real LLM calls)
OPENAI_API_KEY=sk-your-openai-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
# Example for custom OpenAI-compatible provider (GLM):
# OPENAI_BASE_URL=https://api.z.ai/api/coding/paas/v4
OPENAI_MODEL=gpt-4o-mini
# Example GLM models:
# OPENAI_MODEL=glm-4.7
OPENAI_TEMPERATURE=0.2
OPENAI_TIMEOUT=120

# Legacy support (maps to OPENAI_MODEL)
MODEL_NAME=gpt-4o-mini

# Per-agent model configuration (optional, falls back to MODEL_NAME/OPENAI_MODEL)
# MODEL_TRIAGE=gpt-4o-mini
# MODEL_BILLING=gpt-4o
# MODEL_TECHNICAL=gpt-4o-mini
# MODEL_MANAGER=gpt-4o

# Agent Inspector Configuration (optional)
# TRACE_SAMPLE_RATE=1.0
# TRACE_PROFILE=debug

# NOTE: To use real LLM calls:
# 1. Install: uv add openai python-dotenv
# 2. Copy this file: cp examples/.env.example examples/.env
# 3. Edit examples/.env and set OPENAI_API_KEY to your actual API key
# 4. Optionally set OPENAI_BASE_URL and OPENAI_MODEL for your provider
